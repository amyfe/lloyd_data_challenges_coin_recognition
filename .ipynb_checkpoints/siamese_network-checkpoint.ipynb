{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c833b1a7-6a55-4988-96c4-f124b46b04bf",
   "metadata": {},
   "source": [
    "## Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c084809-0d4d-40fa-8adf-d0e85164eda5",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ded6ed7-c9e4-4808-bf2d-cfa9ab759a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (100, 100)  # je nach MÃ¼nzgrÃ¶ÃŸe anpassen\n",
    "def preprocess_image(path):\n",
    "    img = load_img(path, target_size=IMG_SIZE, color_mode='grayscale')\n",
    "    img = img_to_array(img) / 255.0\n",
    "    return img\n",
    "def load_dataset(base_path):\n",
    "    groups = sorted(os.listdir(base_path))\n",
    "    data = {}\n",
    "    for group in groups:\n",
    "        paths = [os.path.join(base_path, group, f) for f in os.listdir(os.path.join(base_path, group))]\n",
    "        data[group] = paths\n",
    "    return data\n",
    "\n",
    "data = load_dataset('./data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d2f9f3-3e59-48c0-91d7-c3d1b11f644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(data):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    groups = list(data.keys())\n",
    "    for group in groups:\n",
    "        images = data[group]\n",
    "        for i in range(len(images)):\n",
    "            img1 = preprocess_image(images[i])\n",
    "\n",
    "            # positive pair\n",
    "            j = (i + 1) % len(images)\n",
    "            img2 = preprocess_image(images[j])\n",
    "            pairs.append([img1, img2])\n",
    "            labels.append(1)\n",
    "\n",
    "            # negative pair\n",
    "            neg_group = random.choice([g for g in groups if g != group])\n",
    "            img2 = preprocess_image(random.choice(data[neg_group]))\n",
    "            pairs.append([img1, img2])\n",
    "            labels.append(0)\n",
    "\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "pairs, labels = make_pairs(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96c23d4-5604-4836-be93-ed0d0f13bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_model(input_shape):\n",
    "    input = Input(input_shape)\n",
    "    x = Conv2D(64, (3,3), activation='relu')(input)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(128, (3,3), activation='relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "input_shape = (IMG_SIZE[0], IMG_SIZE[1], 1)\n",
    "base_model = build_siamese_model(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "feat_a = base_model(input_a)\n",
    "feat_b = base_model(input_b)\n",
    "\n",
    "# Abstand berechnen\n",
    "distance = Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))([feat_a, feat_b])\n",
    "output = Dense(1, activation='sigmoid')(distance)\n",
    "\n",
    "siamese_model = Model(inputs=[input_a, input_b], outputs=output)\n",
    "siamese_model.compile(loss='binary_crossentropy', optimizer=Adam(0.0001), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b28b84-7c5c-49fa-918c-ec2c5750e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pairs[:,0]\n",
    "X2 = pairs[:,1]\n",
    "X1 = np.stack(X1)\n",
    "X2 = np.stack(X2)\n",
    "\n",
    "siamese_model.fit([X1, X2], labels, epochs=10, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2410a7-def6-42d4-9842-3b982659924d",
   "metadata": {},
   "source": [
    "## Datenvorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256463d7-5cfc-43f7-995b-10e22c159272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47fd2c10-c8ae-4301-9355-7421fa53a4c0",
   "metadata": {},
   "source": [
    "## ToDo's\n",
    "\n",
    "Vorverarbeitung\n",
    "\n",
    "    MÃ¼nzen ggf. zentrieren / ausrichten.\n",
    "\n",
    "    Optionale Segmentierung (z.â€¯B. nur Vorderseite/RÃ¼ckseite).\n",
    "\n",
    "    Datenaugmentation (aber vorsichtig â€“ Drehung kann Stempelverzerrung erzeugen).\n",
    "\n",
    "ðŸ’¡ Datenspeicher & Formate\n",
    "\n",
    "    Nutze einheitliches Format (z.â€¯B. .png, Graustufen).\n",
    "\n",
    "    Dateibenennung mit Stempel-ID, wenn verfÃ¼gbar, zur besseren Paarbildung.\n",
    "\n",
    "ðŸ’¡ Unausgewogene Gruppen\n",
    "\n",
    "    GruppengrÃ¶ÃŸe mit Sampling ausgleichen (oversampling oder balancierte Paarbildung).\n",
    "\n",
    "ðŸ’¡ Feature-Speicherung\n",
    "\n",
    "    Nach Training: Embeddings abspeichern und fÃ¼r Vergleich (auch offline) nutzen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
